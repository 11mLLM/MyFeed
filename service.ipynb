{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HkPv60CMUSMA",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@markdown # 개발 환경 확인\n",
        "!nvidia-smi\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzpuDbEr3Y5R"
      },
      "outputs": [],
      "source": [
        "#@markdown # 개발 환경 셋업 test\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  !npm install localtunnel\n",
        "  !pip install diffusers transformers scipy ftfy numpy\n",
        "  !pip install \"ipywidgets>=7,<8\"\n",
        "  !pip install streamlit streamlit-chat\n",
        "  !pip install bardapi\n",
        "  !pip install requests\n",
        "  !pip install deep-translator\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AoldllOQER8_"
      },
      "outputs": [],
      "source": [
        "#@markdown # Hugging Face 로그인\n",
        "from google.colab import output\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "output.enable_custom_widget_manager()\n",
        "notebook_login()\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVm412Vq3wcs",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # Streamlit 어플리케이션 작성\n",
        "%%writefile app.py\n",
        "\n",
        "import json\n",
        "import re\n",
        "import requests\n",
        "import streamlit as st\n",
        "import torch\n",
        "from bardapi.constants import SESSION_HEADERS\n",
        "from bardapi import Bard\n",
        "from deep_translator import GoogleTranslator\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from PIL import Image\n",
        "from torch import autocast\n",
        "\n",
        "MODEL = \"runwayml/stable-diffusion-v1-5\"\n",
        "# MODEL = \"CompVis/stable-diffusion-v1-4\"\n",
        "\n",
        "st.header(\"Service (\" + MODEL + \")\")\n",
        "\n",
        "session = requests.Session()\n",
        "session.headers = SESSION_HEADERS\n",
        "\n",
        "if 'psid' not in st.session_state:\n",
        "    st.session_state['psid'] = \"\"\n",
        "\n",
        "if 'psidts' not in st.session_state:\n",
        "    st.session_state['psidts'] = \"\"\n",
        "\n",
        "if 'psidcc' not in st.session_state:\n",
        "    st.session_state['psidcc'] = \"\"\n",
        "\n",
        "if 'pipe' not in st.session_state:\n",
        "    st.session_state['pipe'] = \"\"\n",
        "\n",
        "if 'prompt' not in st.session_state:\n",
        "    st.session_state['prompt'] = \"화려한 색깔의 선글라스 쓰고 당근을 먹으면서 가상 세계를 즐겁게 여행하는 토끼, 일러스트 스타일, 파란 바탕\"\n",
        "\n",
        "def get_json(json_string):\n",
        "    json_string = json_string.replace('\\n', ' ')\n",
        "    result = re.search('```json(.*)```', json_string)\n",
        "    if result:\n",
        "      return json.loads(result.group(1))\n",
        "    return json.loads(json_string)\n",
        "\n",
        "def generate_prompt_for_stable_diffusion(prompt):\n",
        "  session.cookies.set(\"__Secure-1PSID\", st.session_state.psid)\n",
        "  session.cookies.set(\"__Secure-1PSIDTS\", st.session_state.psidts)\n",
        "  session.cookies.set(\"__Secure-1PSIDCC\", st.session_state.psidcc)\n",
        "\n",
        "  bard = Bard(token=st.session_state.psid, session=session)\n",
        "  prompt_for_generating_stable_diffusion_prompt = '\\\n",
        "    I want you to help me make prompts for the Stable Diffusion.\\\n",
        "    Stable Diffusion is a text-based image generation model that can create diverse and high-quality images based on users\\' requests.\\\n",
        "    In order to get the best results from Stable diffusion, you need to follow some guidelines when composing prompts.\\\n",
        "    Here are some tips for writing prompts for Stable Diffusion:\\\n",
        "    1. Be as specific as possible in the requests. Stable diffusion handles concrete prompts better than abstract or ambiguous ones.\\\n",
        "    For example, instead of \\\\\"portrait of a woman,\\\\\" it is better to write \\\\\"portrait of a Korean woman with brown eyes and red hair in Renaissance style.\\\\\"\\\n",
        "    2. Specify specific art styles or materials. If you want to get an image in a certain style or with a certain texture, then specify this in the request.\\\n",
        "    For example, instead of \\\\\"landscape,\\\\\" it is better to write \\\\\"watercolor landscape with mountains and lake.\\\\\"\\\n",
        "    3. Specify specific artists for reference. If you want to get an image similar to the work of some artist, then specify his name in the request.\\\n",
        "    For example, instead of \\\\\"abstract image,\\\\\" it is better to write \\\\\"abstract image in the style of Picasso.\\\\\"\\\n",
        "    4. Don\\'t use any pronouns.\\\n",
        "    5. Avoid using thesr words: in a, a, an, the, with, of, and, is, of, by\\\n",
        "    6. Weigh your keywords. You can use token: 1.3 to specify the weight of keywords in your query. The greater the weight of the keyword, the more it will affect the result.\\\n",
        "    For example, if you want to get an image of a cat with green eyes and a pink nose, then you can write \\\\\"a cat:1.5, green eyes:1.3, pink nose:1.\\\\\" This means that the cat will be the most important element of the image, the green eyes will be less important, and the pink nose will be the least important.\\\n",
        "    \\\n",
        "    I will also give some examples of good prompts for Stable Diffusion so that you can study them and focus on them.\\\n",
        "    Examples:\\\n",
        "    a cute kitten made out of metal, (cyborg:1.1), ([tail | detailed wire]:1.3), (intricate details), hdr, (intricate details, hyperdetailed:1.2), cinematic shot, vignette, centered\\\n",
        "    medical mask, victorian era, cinematography, intricately detailed, crafted, meticulous, magnificent, maximum details, extremely hyper aesthetic.\\\n",
        "    \\\n",
        "    a Korean girl, wearing a tie, cupcake in her hands, school, indoors, (soothing tones:1.25), (hdr:1.25), (artstation:1.2), dramatic, (intricate details:1.14), (hyperrealistic 3d render:1.16), (filmic:0.55), (rutkowski:1.1), (faded:1.3)\\\n",
        "    \\\n",
        "    a portrait of a laughing, toxic, muscle, god, elder, (hdr:1.28), bald, hyperdetailed, cinematic, warm lights, intricate details, hyperrealistic, dark radial background, (muted colors:1.38), (neutral colors:1.2)\\\n",
        "    \\\n",
        "    Token length of the generated prompt must not be more than 73. The token length is measured relative to the length when using the CLIP model.\\\n",
        "    Also, you should not copy my request directly in your response, you should compose a new one, observing the format given in the examples.\\\n",
        "    Finally, give three prompts always like [\\\\\"prompt_1\\\\\", \\\\\"prompt_2\\\\\", \\\\\"prompt_3\\\\\"].\\\n",
        "    Don\\'t add your comments, but answer right away.\\\n",
        "    let\\'s think step by step.\\\n",
        "    User question: ' + prompt + '\\\n",
        "    Format: {{\\\\\"prompts\\\": [\\\\\"prompt_1\\\\\", \\\\\"prompt_2\\\\\", \\\\\"prompt_3\\\\\"]}}}'\n",
        "  response = bard.get_answer(prompt_for_generating_stable_diffusion_prompt)\n",
        "\n",
        "  st.write(response['content'])\n",
        "  return get_json(response['content'])['prompts']\n",
        "\n",
        "with st.form('form', clear_on_submit = True):\n",
        "  st.session_state.psid = st.text_input('1PSID: ', st.session_state.psid, type = \"password\")\n",
        "  st.session_state.psidts = st.text_input('1PSIDTS: ', st.session_state.psidts, type = \"password\")\n",
        "  st.session_state.psidcc = st.text_input('1PSIDCC: ', st.session_state.psidcc, type = \"password\")\n",
        "  st.session_state.prompt = st.text_input(\"Prompt: \", st.session_state.prompt)\n",
        "  submitted = st.form_submit_button('Generate')\n",
        "\n",
        "if submitted:\n",
        "  genereted_prompts = []\n",
        "  with st.spinner(\"Generating Stable Diffusion Prompt ...\"):\n",
        "    original_prompt = GoogleTranslator(source='auto', target='en').translate(st.session_state.prompt)\n",
        "    genereted_prompts = generate_prompt_for_stable_diffusion(original_prompt)\n",
        "\n",
        "  if st.session_state.pipe == \"\":\n",
        "    with st.spinner(\"Loading \" + MODEL + \"...\"):\n",
        "      # make sure you're logged in with `huggingface-cli login`\n",
        "      st.session_state.pipe = StableDiffusionPipeline.from_pretrained(MODEL, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True)\n",
        "      st.session_state.pipe = st.session_state.pipe.to(\"cuda\")\n",
        "\n",
        "  num_rows = 1\n",
        "  num_cols = 3\n",
        "  all_images = []\n",
        "  with st.spinner(\"Generating \" + st.session_state.prompt + \"...\"):\n",
        "    for i in range(num_rows):\n",
        "      with autocast(\"cuda\"):\n",
        "        image = st.session_state.pipe(genereted_prompts, guidance_scale=8.0, num_inference_steps=25, height=512, width=512).images\n",
        "      all_images.extend(image)\n",
        "\n",
        "  col1, col2, col3 = st.columns(3)\n",
        "  with col1:\n",
        "    st.image(all_images[0], caption = GoogleTranslator(source='auto', target='ko').translate(genereted_prompts[0]), use_column_width=\"auto\", clamp=False, channels=\"RGB\", output_format=\"auto\")\n",
        "\n",
        "  with col2:\n",
        "    st.image(all_images[1], caption = GoogleTranslator(source='auto', target='ko').translate(genereted_prompts[1]), use_column_width=\"auto\", clamp=False, channels=\"RGB\", output_format=\"auto\")\n",
        "\n",
        "  with col3:\n",
        "    st.image(all_images[2], caption = GoogleTranslator(source='auto', target='ko').translate(genereted_prompts[2]), use_column_width=\"auto\", clamp=False, channels=\"RGB\", output_format=\"auto\")\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sqG9cYZ54Ndm"
      },
      "outputs": [],
      "source": [
        "#@markdown # 웹 어플리케이션 구동\n",
        "#@markdown ##### /content/logs.txt External URL 주소 필요\n",
        "!streamlit run /content/app.py &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501\n",
        "\n",
        "#@markdown ---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}